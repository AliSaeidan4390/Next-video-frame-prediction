{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213bd5b1-aea2-4086-8271-33b39c17c420",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########################################  Model for training   ###################################################################\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Force TensorFlow to use CPU before loading anything else\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.image import ssim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Allow memory growth for the GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(\"Memory growth enabled for GPU\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error enabling memory growth: {e}\")\n",
    "\n",
    "# Function to resize the frames to a target size (340, 300)\n",
    "def resize_frame(frame, target_size=(140, 100)):\n",
    "    \"\"\"\n",
    "    Resize the frame to the target size (300, 387) explicitly ensuring the correct dimensions.\n",
    "    \"\"\"\n",
    "    if frame is None or frame.shape[0] == 0 or frame.shape[1] == 0:\n",
    "        print(f\"âš  Invalid frame detected: {frame}\")\n",
    "        return None  # Return None for invalid frames\n",
    "    \n",
    "    height, width = frame.shape[:2]\n",
    "    \n",
    "    # Ensure resizing happens correctly (force it to target size)\n",
    "    if (height, width) != target_size:\n",
    "        print(f\"âš  Resizing: {frame.shape} -> {target_size}\")\n",
    "        frame = cv2.resize(frame, (target_size[1], target_size[0]))  # Resize to (300, 387)\n",
    "    \n",
    "    return frame  # Return the resized frame\n",
    "\n",
    "# ConvLSTM Model definition\n",
    "seq = keras.Sequential([\n",
    "    keras.Input(shape=(None, 140, 100, 1)),  # Input shape is now (None, 300, 387, 1)\n",
    "    layers.ConvLSTM2D(filters=50, kernel_size=(5, 5), padding=\"same\", return_sequences=True),\n",
    "    layers.LeakyReLU(alpha=0.1),\n",
    "    layers.Dropout(0.2),\n",
    "\n",
    "    layers.ConvLSTM2D(filters=50, kernel_size=(5, 5), padding=\"same\", return_sequences=True),\n",
    "    layers.LeakyReLU(alpha=0.1),\n",
    "    layers.Dropout(0.2),\n",
    "\n",
    "    layers.ConvLSTM2D(filters=50, kernel_size=(5, 5), padding=\"same\", return_sequences=True),\n",
    "    layers.LeakyReLU(alpha=0.1),\n",
    "    layers.Dropout(0.2),\n",
    "\n",
    "    layers.Conv3D(filters=1, kernel_size=(1, 3, 3), activation=\"sigmoid\", padding=\"same\"),\n",
    "])\n",
    "\n",
    "# Implement EarlyStopping and ReduceLROnPlateau\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.8, patience=8)\n",
    "\n",
    "\n",
    "# Compute difference between consecutive frames to enforce motion consistency\n",
    "@keras.utils.register_keras_serializable()\n",
    "def temporal_loss(y_true, y_pred):\n",
    "    diff_true = y_true[:, 1:] - y_true[:, :-1]\n",
    "    diff_pred = y_pred[:, 1:] - y_pred[:, :-1]\n",
    "    diff_diff = diff_true - diff_pred\n",
    "\n",
    "    # Use Huber loss on the difference between consecutive frames\n",
    "    huber_loss = tf.keras.losses.Huber(delta=1.0)  # You can adjust the delta value\n",
    "    loss_value = huber_loss(diff_true, diff_pred)\n",
    "\n",
    "    return tf.reduce_mean(loss_value)\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # Clip predictions and ground truth to avoid extreme values\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-6, 1.0 - 1e-6)\n",
    "    y_true = tf.clip_by_value(y_true, 1e-6, 1.0 - 1e-6)\n",
    "    \n",
    "    # Compute SSIM loss safely\n",
    "    ssim_loss = 1 - tf.reduce_mean(ssim(y_true, y_pred, max_val=1.0, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03))+ 1e-8\n",
    "    \n",
    "    # Compute MSE loss\n",
    "    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))+ 1e-8\n",
    "    \n",
    "    # Compute Temporal Loss\n",
    "    temp_loss = temporal_loss(y_true, y_pred)+ 1e-8\n",
    "    #############\n",
    "    # âœ… Immediately detect NaNs/Infs\n",
    "    mse_loss = tf.debugging.check_numerics(mse_loss, \"NaN detected in MSE loss\")\n",
    "    temp_loss = tf.debugging.check_numerics(temp_loss, \"NaN detected in Temporal loss\")\n",
    "    ssim_loss = tf.debugging.check_numerics(ssim_loss, \"NaN detected in SSIM loss\")\n",
    "    # Weighted sum of losses\n",
    "    total_loss = ssim_loss + 0.1 * mse_loss + 0.2 * temp_loss\n",
    "    #total_loss = ssim_loss + 0.05 * temp_loss\n",
    "    return total_loss\n",
    "\n",
    "# Compile Model with reduced learning rate\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.005, clipnorm=1.0)  # Reduced learning rate\n",
    "seq.compile(loss=custom_loss, optimizer=optimizer)\n",
    "seq.summary()\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "# Function to load available frames from the dataset\n",
    "def get_available_frames(folder_path):\n",
    "    frame_numbers = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.startswith(\"frame_\") and file_name.endswith(\".png\"):\n",
    "            try:\n",
    "                frame_num = int(file_name.split(\"_\")[1].split(\".\")[0])\n",
    "                frame_numbers.append(frame_num)\n",
    "            except ValueError:\n",
    "                continue  # Skip files with invalid naming\n",
    "    return sorted(frame_numbers)\n",
    "\n",
    "# Function to resize frames to a fixed size\n",
    "def resize_frame(frame, target_size=(340, 300)):\n",
    "    return cv2.resize(frame, target_size)\n",
    "\n",
    "def load_image_sequence(folder_path, n_frames=20, start_frame=0, target_size=(140, 100)):\n",
    "    \"\"\"\n",
    "    Loads a sequence of images from the specified folder.\n",
    "    If a frame is missing, it appends a black frame instead.\n",
    "    Handles non-sequential frame numbering.\n",
    "    \"\"\"\n",
    "    # List all frames in the folder\n",
    "    all_frames = [f for f in os.listdir(folder_path) if f.endswith('.png')]\n",
    "    \n",
    "    # Sort the frames based on their numeric frame number (extract number from filename)\n",
    "    all_frames.sort(key=lambda x: int(x.split('_')[1].split('.')[0]))  # Extract frame number from filename\n",
    "    \n",
    "    sequence = []\n",
    "    \n",
    "    # Ensure we start from the right frame\n",
    "    for i in range(start_frame, start_frame + n_frames):\n",
    "        if i < len(all_frames):\n",
    "            image_path = os.path.join(folder_path, all_frames[i])\n",
    "            \n",
    "            # Read the image and resize it to the target size\n",
    "            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale\n",
    "            img = cv2.resize(img, target_size)  # Resize to target size\n",
    "            \n",
    "            # Append the frame to the sequence\n",
    "            sequence.append(img)\n",
    "        else:\n",
    "            # If the frame is missing, append a black frame of the correct size\n",
    "            print(f\"âš  Missing frame index {i}, using black frame\")\n",
    "            black_frame = np.zeros(target_size, dtype=np.uint8)  # Black frame with target size\n",
    "            sequence.append(black_frame)\n",
    "    \n",
    "    # Ensure that all frames are the same shape before converting to numpy array\n",
    "    for idx, frame in enumerate(sequence):\n",
    "        print(f\"Frame {idx} shape: {frame.shape}\")  # Debugging frame shape\n",
    "\n",
    "    # Convert to a numpy array of shape (n_frames, height, width)\n",
    "    return np.array(sequence)\n",
    "\n",
    "# Memory efficient frame loading: Load a batch of frames\n",
    "def load_batch_of_frames(batch_size, folder_path, n_frames=20, target_size=(140, 100)):\n",
    "    \"\"\"\n",
    "    Loads a batch of frames from the specified folder, ensuring memory efficiency.\n",
    "    \"\"\"\n",
    "    # List all frames in the folder\n",
    "    all_frames = [f for f in os.listdir(folder_path) if f.endswith('.png')]\n",
    "    all_frames.sort(key=lambda x: int(x.split('_')[1].split('.')[0]))  # Sort by frame number\n",
    "    \n",
    "    batch = []\n",
    "    for idx in range(batch_size):\n",
    "        # Randomly pick a starting frame for this sample\n",
    "        start_frame = np.random.randint(0, len(all_frames) - n_frames + 1)\n",
    "        \n",
    "        sequence = []\n",
    "        for i in range(start_frame, start_frame + n_frames):\n",
    "            image_path = os.path.join(folder_path, all_frames[i])\n",
    "            \n",
    "            # Read and resize the frame\n",
    "            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = resize_frame(img, target_size)\n",
    "            \n",
    "            sequence.append(img)\n",
    "        \n",
    "        # Add this sequence to the batch\n",
    "        batch.append(np.array(sequence))\n",
    "    \n",
    "    # Return the batch as a numpy array\n",
    "    return np.array(batch)\n",
    "\n",
    "# Generate movies from multiple folders with memory efficient batch loading\n",
    "def generate_movies_from_multiple_folders(folder_paths, n_samples_per_folder=30, n_frames=20, batch_size=1, target_size=(100, 140)):\n",
    "    noisy_movies = []\n",
    "    shifted_movies = []\n",
    "\n",
    "    for folder_path in folder_paths:\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"âŒ Folder not found: {folder_path}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"ðŸ“‚ Processing folder: {folder_path}\")\n",
    "\n",
    "        for sample_idx in range(n_samples_per_folder):\n",
    "            try:\n",
    "                # Load a batch of frames from the folder\n",
    "                movie_frames_batch = load_batch_of_frames(batch_size, folder_path, n_frames=n_frames, target_size=target_size)\n",
    "\n",
    "                # For each batch, create noisy and shifted movies\n",
    "                for movie_frames in movie_frames_batch:\n",
    "                    noisy_movies.append(movie_frames)\n",
    "                    shifted_movie = movie_frames[1:]\n",
    "\n",
    "                    # Ensure the output has the same number of frames\n",
    "                    if shifted_movie.shape[0] < n_frames:\n",
    "                        shifted_movie = np.concatenate((shifted_movie, np.expand_dims(movie_frames[-1], axis=0)), axis=0)\n",
    "\n",
    "                    shifted_movies.append(shifted_movie)\n",
    "\n",
    "                print(f\"   âœ… Sample {sample_idx + 1}/{n_samples_per_folder} from {folder_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error loading sequence from {folder_path}, sample {sample_idx + 1}: {e}\")\n",
    "                continue\n",
    "\n",
    "    print(f\"ðŸ“Š Total noisy movies collected: {len(noisy_movies)}\")\n",
    "    print(f\"ðŸ“Š Total shifted movies collected: {len(shifted_movies)}\")\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    noisy_movies = np.array(noisy_movies)\n",
    "    shifted_movies = np.array(shifted_movies)\n",
    "\n",
    "    # Add the channel dimension (grayscale)\n",
    "    noisy_movies = noisy_movies[..., np.newaxis]\n",
    "    shifted_movies = shifted_movies[..., np.newaxis]\n",
    "\n",
    "    return noisy_movies, shifted_movies\n",
    "\n",
    "# Define the dataset folder paths\n",
    "dataset_folders = [\n",
    "    r\"/mnt/ssd/Ulster/Vision Project/Papers/Report 2/Datasets/al5083/train/170815-133921-Al 2mm\",\n",
    "    r\"/mnt/ssd/Ulster/Vision Project/Papers/Report 2/Datasets/al5083/train/170815-134756-Al 2mm\",\n",
    "    r\"/mnt/ssd/Ulster/Vision Project/Papers/Report 2/Datasets/al5083/train/170904-112347-Al 2mm\",\n",
    "    r\"/mnt/ssd/Ulster/Vision Project/Papers/Report 2/Datasets/al5083/train/170904-113012-Al 2mm-part1\",\n",
    "    r\"/mnt/ssd/Ulster/Vision Project/Papers/Report 2/Datasets/al5083/train/170904-141232-Al 2mm-part3\",\n",
    "    r\"/mnt/ssd/Ulster/Vision Project/Papers/Report 2/Datasets/al5083/train/170904-141730-Al 2mm-part3\",\n",
    "    r\"/mnt/ssd/Ulster/Vision Project/Papers/Report 2/Datasets/al5083/train/170906-113317-Al 2mm-part3\",\n",
    "    r\"/mnt/ssd/Ulster/Vision Project/Papers/Report 2/Datasets/al5083/train/170906-153326-Al 2mm-part2\",\n",
    "    r\"/mnt/ssd/Ulster/Vision Project/Papers/Report 2/Datasets/al5083/train/170913-143933-Al 2mm-part2\",\n",
    "    r\"/mnt/ssd/Ulster/Vision Project/Papers/Report 2/Datasets/al5083/train/170913-151508-Al 2mm-part1\"\n",
    "]\n",
    "\n",
    "# Generate noisy and shifted movies\n",
    "noisy_movies, shifted_movies = generate_movies_from_multiple_folders(dataset_folders, n_samples_per_folder=30, n_frames=20, target_size=(100, 140))\n",
    "\n",
    "# Print the shapes to verify\n",
    "print(\"Noisy movies shape:\", noisy_movies.shape)  # Expected: (40, 20, 340, 300, 1) if all folders are used\n",
    "print(\"Shifted movies shape:\", shifted_movies.shape)  # Expected: (40, 20, 340, 300, 1) if all folders are used \n",
    "\n",
    "###############################################################################################################################\n",
    "print(f\"Shape of noisy_movies: {noisy_movies.shape}\")\n",
    "print(f\"Shape of shifted_movies: {shifted_movies.shape}\")\n",
    "\n",
    "# Ensure shape is (batch_size, time_steps, height, width, 1)\n",
    "noisy_movies_resized = noisy_movies  # No need for np.newaxis since last dim is already 1\n",
    "shifted_movies_resized = shifted_movies  # No need for np.newaxis\n",
    "\n",
    "# Print shape to verify correctness\n",
    "print(f\"Final Noisy Movies Shape: {noisy_movies_resized.shape}\")\n",
    "print(f\"Final Shifted Movies Shape: {shifted_movies_resized.shape}\")\n",
    "\n",
    "# Visualization\n",
    "num_frames = 5\n",
    "sample_noisy = noisy_movies[0, :num_frames]  # First sample's first five frames\n",
    "sample_shifted = shifted_movies[0, :num_frames]  # First sample's first five frames (shifted)\n",
    "\n",
    "#fig, axes = plt.subplots(2, num_frames, figsize=(15, 6))\n",
    "#for i in range(num_frames):\n",
    "   # axes[0, i].imshow(sample_noisy[i].squeeze(), cmap=\"gray\")\n",
    "   # axes[0, i].set_title(f\"Noisy Frame {i+1}\")\n",
    "    #axes[0, i].axis(\"off\")\n",
    "    \n",
    "   # axes[1, i].imshow(sample_shifted[i].squeeze(), cmap=\"gray\")\n",
    "   # axes[1, i].set_title(f\"Shifted Frame {i+1}\")\n",
    "   # axes[1, i].axis(\"off\")\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()\n",
    "######################################################################################\n",
    "noisy_movies_resized = noisy_movies_resized.astype('float32')\n",
    "shifted_movies_resized = shifted_movies_resized.astype('float32')\n",
    "noisy_movies_resized = noisy_movies_resized.reshape((noisy_movies_resized.shape[0], 20, 140, 100, 1))\n",
    "shifted_movies_resized = shifted_movies_resized.reshape((shifted_movies_resized.shape[0], 20, 140, 100, 1))\n",
    "print(noisy_movies_resized.shape)  # Should print (num_samples, 20, 340, 300, 1)\n",
    "print(shifted_movies_resized.shape)  # Should print (num_samples, 20, 340, 300, 1)\n",
    "#####################\n",
    "\n",
    "#############Normalization #####################\n",
    "\n",
    "noisy_movies_resized = noisy_movies_resized / 255.0\n",
    "shifted_movies_resized = shifted_movies_resized / 255.0\n",
    "\n",
    "#######################################################################\n",
    "num_frames = 5\n",
    "sample_noisy2 = noisy_movies_resized[0, :num_frames]  # First sample's first five frames\n",
    "sample_shifted2 = shifted_movies_resized[0, :num_frames]  # First sample's first five frames (shifted)\n",
    "\n",
    "fig, axes = plt.subplots(2, num_frames, figsize=(15, 6))\n",
    "for i in range(num_frames):\n",
    "    axes[0, i].imshow(sample_noisy[i].squeeze(), cmap=\"gray\")\n",
    "    axes[0, i].set_title(f\"Noisy Frame {i+1}\")\n",
    "    axes[0, i].axis(\"off\")\n",
    "    \n",
    "    axes[1, i].imshow(sample_shifted[i].squeeze(), cmap=\"gray\")\n",
    "    axes[1, i].set_title(f\"Shifted Frame {i+1}\")\n",
    "    axes[1, i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "###################################################\n",
    "\n",
    "# Print available logs during training to check if val_loss is being computed\n",
    "def on_epoch_end(epoch, logs=None):\n",
    "    print(f\"Epoch {epoch} - Available logs: {logs.keys()}\")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.8, patience=13),\n",
    "    keras.callbacks.LambdaCallback(on_epoch_end=on_epoch_end)  # Debug logs at each epoch\n",
    "]\n",
    "\n",
    "seq.fit(\n",
    "    noisy_movies_resized, \n",
    "    shifted_movies_resized, \n",
    "    batch_size=1,\n",
    "    epochs=30,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Save Model\n",
    "seq.save(\"conv_lstm_model-38.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
